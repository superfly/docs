---
title: LiteFS Example Application
layout: docs
sitemap: false
nav: litefs
toc: true
---

<%= partial "partials/disclaimer" %>

This tutorial will get you up and running with an example application that uses
LiteFS on Fly.io. While using Fly.io is not required, it provides services such
as Consul that make it easy to run LiteFS with minimal configuration. It should
take you about 10 minutes to go through this tutorial.


## Prerequisites

First, you'll need to install [`flyctl`](/docs/hands-on/install-flyctl/).
Then, either sign up or log in:

```sh
# Sign up for a new account.
fly auth signup
```

```sh
# Or sign in with an existing account.
fly auth login
```

Once the CLI is ready, you'll need to download the [`litefs-example`](https://github.com/superfly/litefs-example)
repository. The app will give you a simple Go & SQLite app that can utilize
LiteFS' distributed database layer.

```sh
git clone https://github.com/superfly/litefs-example
cd litefs-example
```

## Deploying your app

### Creating your application

First, we'll need to create our application on Fly.io:

```sh
fly apps create my-litefs-app
```

Your application name will need to be unique. You can also specify the
`--autogenerate-name` flag and Fly.io will generate a name for you.


### Creating a volume

Next, we need to set up a persistent volume so that our data is not lost between
restarts. Be sure to replace the `-a` value with your application name.

```sh
fly volumes create -a my-litefs-app -r den --size 1 litefs
```

This will create a 1GB volume in Denver (`den`) called `"litefs"` for your
application.


### Set up your Fly.io config

Once you have your app created, create a new `fly.toml` file in the root with
the following contents. **Make sure to set the correct app name!**

```toml
app = "my-litefs-app"

[experimental]
  enable_consul = true

[[services]]
  internal_port = 8080
  protocol = "tcp"

  [[services.ports]]
    handlers = ["http"]
    port = 80
    force_https = true

  [[services.ports]]
    handlers = ["tls", "http"]
    port = "443"

[mounts]
  source = "litefs"
  destination = "/var/lib/litefs"
```

This config will give you a Consul endpoint to use with LiteFS and it will
configure your application so it's publicly visible over HTTPS. It also mounts
the `litefs` volume to the `/var/lib/litefs` path.


### Launching your app

The next step is to launch & deploy your app with the following command:

```sh
fly deploy
```

The application should build and deploy and you should see it up in running
after a minute or so. You can go to `https://$APPNAME.fly.dev/` and see your
application running live.

The application is a simple interface for generating fake records. It's just
for illustrating how LiteFS can easily replicate your data between nodes.

When you click the _"Generate Record"_ button, it will create that row in a
local SQLite database that is running on a LiteFS file system. Any other node
running LiteFS will automatically get those updates and apply them to their
local copy of the database. That lets every node keep an exact copy of the same
database.

## Scaling up your app

Right now we only have 1 instance of our application running in Denver. Let's
add more regions in London (`lhr`) and Sydney (`syd`) by creating volumes:

```sh
fly volumes create -r lhr --size 1 litefs
```

```sh
fly volumes create -r syd --size 1 litefs
```

Now that volumes are created, we can increase our scale count and Fly.io will
start VMs attached to those volumes:

```sh
fly scale count 3
```

You can use `fly status` or `fly logs` to monitor for the new nodes to startup
and join the cluster automatically.

LiteFS uses [Consul](https://www.consul.io/) to track the current primary node
in the cluster. Other nodes will automatically find the primary on startup and
connect to it and replicate from it. In the event that the primary node fails,
it will lose its "primary" status and another node can become primary.

The LiteFS FUSE directory (`/litefs`) provides a file called `.primary` that
provides the hostname of the current primary node. The application can use this
to redirect write requests to the primary node and the replica node can service
any read-only requests.

While replication is fast, it's possible that a write to a primary will not get
replicated before refreshing the page on the replica. One option to get around
this is to read from the primary for a few seconds after a write to give the
replica time to receive the change.


## Watching real-time replication

Fly.io will automatically connect you to the closest region in order to minimize
latency. If you're in Europe, you'll connect to the `lhr` region. If you're in
Australia, you'll connect to the `syd` region.

However, we want to see that our data replicates to each region. For that, we've
added a `region` query parameter to our application's logic. If you want to view
the application from the `lhr` region, you can navigate to:

```
https://$APPNAME.fly.dev?region=lhr
```

Replication in LiteFS is fast so let's set up real-time updates using the
[`watch`](https://linux.die.net/man/1/watch) command in our terminal. If you're
using macOS, you may need to install it using `brew install watch`.

The `watch` command will continuously run a subcommand and display its output
until we stop it with `CTRL-C`.

We'll be running a cURL command to continuously fetch our app's data every 100ms
so we can see updates as they happen. Open a new terminal window for each of
your regions and run the following (except change the "region" at the end):

```sh
watch -n 0.1 "curl -s -H 'Accept: text/plain' https://${APPNAME}.fly.dev?region=lhr"
```

Now, when you click on the _"Generate Record"_ in your browser, you should see
your other nodes update with new data almost instantly. The time to update is
approximately the ping time. For example, a ping from London to Sydney is
around 250ms.


## Restrict where primaries can exist

By default, all nodes in the cluster can become the primary. However, in
practice this may not be ideal. Suddenly moving application writes half way
around the world can have affects on performance.

Instead, you can restrict which nodes can become primary by setting the
`candidate` config field to `true`. Non-eligible nodes should set the value to
`false`.

LiteFS also provides some basic environment variable expression evaluation so
you can set the field like this:

```yml
lease:
  candidate: ${FLY_REGION == "den"}
```

Make sure you have at least 2 volumes created in Denver so that the primary
status can move between those two. Otherwise, you'll see temporary write
availability loss when you deploy your application.

